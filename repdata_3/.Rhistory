row(rnk[fed[fed[, 3] == 'High income: OECD', 1], ])
which(fed[fed[, 3] == 'High income: OECD')
which(fed[fed[, 3] == 'High income: OECD'])
rnk[fed[fed[, 3] == 'High income: OECD', 1], ]
fed[fed[, 3] == 'High income: OECD', 1]
which(rnk.X == fed[fed[, 3] == 'High income: OECD', 1])
which(rnk$X == fed[fed[, 3] == 'High income: OECD', 1])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "temp.csv", method = "curl")
gdp <- read.csv("temp.csv", skip = 4, stringsAsFactors=FALSE)
head(gdp)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile = "temp.csv", method = "curl")
fed <- read.csv("temp.csv", stringsAsFactors=FALSE)
length(intersect(fed[, 1], head(gdp, 190)[, 1]))
gdp$X.4<- gsub(",", "", gdp$X.4)
gdp$X.4<- as.numeric(gdp$X.4)
rnk = arrange(head(gdp, 190), X.4)
head(rnk, 14)
which(rnk$X == fed[fed[, 3] == 'High income: OECD', 1])
fed[fed[, 3] == 'High income: OECD', 1]
rnk$X
which(rnk$X %in% fed[fed[, 3] == 'High income: OECD', 1])
mean(which(rnk$X %in% fed[fed[, 3] == 'High income: OECD', 1]))
mean(which(rnk$X %in% fed[fed[, 3] == 'High income: nonOECD', 1]))
rnk(head)
head(rnk)
rnk
rnk$X %in% fed[fed[, 3] == 'High income: OECD', 1]
rnk = arrange(head(gdp, 190), desc(X.4))
mean(which(rnk$X %in% fed[fed[, 3] == 'High income: nonOECD', 1]))
mean(which(rnk$X %in% fed[fed[, 3] == 'High income: OECD', 1]))
rank
rnk
?quantile
seq(0, 1, lenght = 5)
seq(0, 1, length = 5)
seq(0, 1, length = 6)
fed
names(fed)
names(fed$Income.Group)
fed$Income.Group
rnk$X %in% fed[fed[, 3] == 'Lower middle income', 1]
rank
rnk
rank
rnk
rnk$X %in% fed[fed[, 3] == 'Lower middle income', 1]
which(rnk$X %in% fed[fed[, 3] == 'Lower middle income', 1])
which(rnk$X %in% fed[fed[, 3] == 'Lower middle income', 1]) < 39
sum(which(rnk$X %in% fed[fed[, 3] == 'Lower middle income', 1]) < 39)
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- "./"
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
getwd()
getwd()
folder <- 'Desktop/r/rprog_3'
require(dplyr)
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- 'Desktop/r/rprog_3'
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
train_x <- read.table(paste(folder,"train/X_train.txt", sep = ""))
train_y <- read.table(paste(folder,"train/y_train.txt", sep = ""))
## Read records from the Test Folder
test_1 <- read.table(paste(folder,"test/subject_test.txt", sep = ""))
test_x <- read.table(paste(folder,"test/X_test.txt", sep = ""))
test_y <- read.table(paste(folder,"test/y_test.txt", sep = ""))
## Fetch the name of the features (Columns) & names of Labels
features <- read.table(paste(folder,"features.txt", sep = ""))
alabels <- read.table(paste(folder,"activity_labels.txt", sep = ""))
## Convert Features column from Factor to Character
## Clean the names of features and save in new variable 'mrgd'
features$V2 <- as.character(features$V2)
mrgd <- features
mrgd$V2 <- gsub("-",".",mrgd$V2)
mrgd$V2 <- gsub("\\(\\)","",mrgd$V2)
## Find Positions of Columns with Mean or Standard Deviation only
meanstd_list <- grep(mrgd$V2, pattern = "(\\.mean\\.)|(\\.std\\.)", ignore.case = T)
## Add 2 to the position, since two new columns will bind to the LEFT
meanstd_list <- meanstd_list + 2;
## Merge Test & Train datasets together (Data, Subjects, Labels)
indata <- rbind(test_x,train_x)
subdata <- rbind(test_1,train_1)
labdata <- rbind(test_y,train_y)
## Assign Column names from Feature List
colnames(indata) <- mrgd$V2
## Bind Test Labels (labdata) & Subjects (subdata) to the LEFT
final <- cbind(subdata$V1, indata)
final <- cbind(labdata$V1, final)
## Rename the new Column Names
colnames(final)[2] <- "Subject"
colnames(final)[1] <- "Label"
## Subset only Means & Standard Deviations, from list of positions 'meanstd_list'
clean_data <- final[,c(1,2,meanstd_list)]
## Merge Label Names dataframe with the data
## Match Label Number 'V1' (from list of labels) to Label code (from Cleaned Data)
finale <- merge(alabels,clean_data, by.y = "Label", by.x="V1")
## Rename Column names V1, V2 to more descriptive names
finale <- rename(finale, LabelName = V2, LabelCode = V1)
tidy <- aggregate(finale, by=list(Activity = finale$LabelName, Subject=finale$Subject), mean)
# Clean again
clean_tidy <- tidy[,-c(3,4,5)]
# Output to file, without row names.
write.table(clean_tidy, file = "./SportDataset.txt",row.name=FALSE)
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- 'Desktop/r/rprog_3/'
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
train_x <- read.table(paste(folder,"train/X_train.txt", sep = ""))
train_y <- read.table(paste(folder,"train/y_train.txt", sep = ""))
## Read records from the Test Folder
test_1 <- read.table(paste(folder,"test/subject_test.txt", sep = ""))
test_x <- read.table(paste(folder,"test/X_test.txt", sep = ""))
test_y <- read.table(paste(folder,"test/y_test.txt", sep = ""))
## Fetch the name of the features (Columns) & names of Labels
features <- read.table(paste(folder,"features.txt", sep = ""))
alabels <- read.table(paste(folder,"activity_labels.txt", sep = ""))
## Convert Features column from Factor to Character
## Clean the names of features and save in new variable 'mrgd'
features$V2 <- as.character(features$V2)
mrgd <- features
mrgd$V2 <- gsub("-",".",mrgd$V2)
mrgd$V2 <- gsub("\\(\\)","",mrgd$V2)
## Find Positions of Columns with Mean or Standard Deviation only
meanstd_list <- grep(mrgd$V2, pattern = "(\\.mean\\.)|(\\.std\\.)", ignore.case = T)
## Add 2 to the position, since two new columns will bind to the LEFT
meanstd_list <- meanstd_list + 2;
## Merge Test & Train datasets together (Data, Subjects, Labels)
indata <- rbind(test_x,train_x)
subdata <- rbind(test_1,train_1)
labdata <- rbind(test_y,train_y)
## Assign Column names from Feature List
colnames(indata) <- mrgd$V2
## Bind Test Labels (labdata) & Subjects (subdata) to the LEFT
final <- cbind(subdata$V1, indata)
final <- cbind(labdata$V1, final)
## Rename the new Column Names
colnames(final)[2] <- "Subject"
colnames(final)[1] <- "Label"
## Subset only Means & Standard Deviations, from list of positions 'meanstd_list'
clean_data <- final[,c(1,2,meanstd_list)]
## Merge Label Names dataframe with the data
## Match Label Number 'V1' (from list of labels) to Label code (from Cleaned Data)
finale <- merge(alabels,clean_data, by.y = "Label", by.x="V1")
## Rename Column names V1, V2 to more descriptive names
finale <- rename(finale, LabelName = V2, LabelCode = V1)
tidy <- aggregate(finale, by=list(Activity = finale$LabelName, Subject=finale$Subject), mean)
# Clean again
clean_tidy <- tidy[,-c(3,4,5)]
# Output to file, without row names.
write.table(clean_tidy, file = "./SportDataset.txt",row.name=FALSE)
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- 'Desktop/r/rprog_3/'
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- 'Desktop/r/rprog_3/UCI HAR Dataset'
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- 'Desktop/r/rprog_3/UCI HAR Dataset/'
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
require(dplyr)
## Folder or subfolder containing the data
## Default: current working directory
folder <- 'Desktop/r/rprog_3/UCI HAR Dataset/'
## Read records from the Train Folder
train_1 <- read.table(paste(folder,"train/subject_train.txt", sep = ""))
train_x <- read.table(paste(folder,"train/X_train.txt", sep = ""))
train_y <- read.table(paste(folder,"train/y_train.txt", sep = ""))
## Read records from the Test Folder
test_1 <- read.table(paste(folder,"test/subject_test.txt", sep = ""))
test_x <- read.table(paste(folder,"test/X_test.txt", sep = ""))
test_y <- read.table(paste(folder,"test/y_test.txt", sep = ""))
## Fetch the name of the features (Columns) & names of Labels
features <- read.table(paste(folder,"features.txt", sep = ""))
alabels <- read.table(paste(folder,"activity_labels.txt", sep = ""))
## Convert Features column from Factor to Character
## Clean the names of features and save in new variable 'mrgd'
features$V2 <- as.character(features$V2)
mrgd <- features
mrgd$V2 <- gsub("-",".",mrgd$V2)
mrgd$V2 <- gsub("\\(\\)","",mrgd$V2)
## Find Positions of Columns with Mean or Standard Deviation only
meanstd_list <- grep(mrgd$V2, pattern = "(\\.mean\\.)|(\\.std\\.)", ignore.case = T)
## Add 2 to the position, since two new columns will bind to the LEFT
meanstd_list <- meanstd_list + 2;
## Merge Test & Train datasets together (Data, Subjects, Labels)
indata <- rbind(test_x,train_x)
subdata <- rbind(test_1,train_1)
labdata <- rbind(test_y,train_y)
## Assign Column names from Feature List
colnames(indata) <- mrgd$V2
## Bind Test Labels (labdata) & Subjects (subdata) to the LEFT
final <- cbind(subdata$V1, indata)
final <- cbind(labdata$V1, final)
## Rename the new Column Names
colnames(final)[2] <- "Subject"
colnames(final)[1] <- "Label"
## Subset only Means & Standard Deviations, from list of positions 'meanstd_list'
clean_data <- final[,c(1,2,meanstd_list)]
## Merge Label Names dataframe with the data
## Match Label Number 'V1' (from list of labels) to Label code (from Cleaned Data)
finale <- merge(alabels,clean_data, by.y = "Label", by.x="V1")
## Rename Column names V1, V2 to more descriptive names
finale <- rename(finale, LabelName = V2, LabelCode = V1)
tidy <- aggregate(finale, by=list(Activity = finale$LabelName, Subject=finale$Subject), mean)
# Clean again
clean_tidy <- tidy[,-c(3,4,5)]
# Output to file, without row names.
write.table(clean_tidy, file = "./SportDataset.txt",row.name=FALSE)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
?tbl_df
tbl_df
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -5:20)
select(cran, -5:20)
select(cran, -(5:20))
-5:20
-(5:20)
select(cran, -(5:20))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 & r_os = 'linux_gnu')
filter(cran, size > 100500 & r_os == 'linux_gnu')
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(ip_id, package, size)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
avg_byte
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package)
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique < 465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, ~grade)
gather(students, sex, count, -grade)
students2
res <- gather()
res2 <- gather(students2, sex_class, count)
res2 <- gather(students2, sex_class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
submit()
students3
?gather
students3
submit()
submit()
students3
submit()
submit()
submit()
reset()
submit()
submit()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
packageVersion('dplyr')
bind_rows(passed, failed)
sat
?separate
submit()
submit()
?separate
?select
submit()
submit()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv "
download.file(fileUrl, destfile = "temp.csv", method = "curl")
temp <- read.csv("temp.csv")
names(temp)
?str_split
strsplit()
?strsplit
strsplit(names(temp), "wgtp")
strsplit(names(temp), "wgtp")[123, ]
strsplit(names(temp), "wgtp")[123]
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv "
download.file(fileUrl, destfile = "temp.csv", method = "curl")
temp <- read.csv("temp.csv")
temp
temp[1:4, ]
temp[1:5, ]
temp[5:195, ]
temp[5:194, 5]
sub(",", "", temp[5:194, 5])
gsub(",", "", temp[5:194, 5])
mean(as.numeric(gsub(",", "", temp[5:194, 5])))
temp
grep("^United",temp[5:194, 2])
temp[5:194, 2]
temp[5:194, 3]
temp[5:194, 1]
temp[5:194, 2]
temp
names(temp)
grep("^United",temp[5:194, 4])
temp[5:194, 4]
library(dyplr)
library(dplyr)
arrange
arrange(temp[5:194, 4])
t <- temp[5:194, 4]
t
t <- temp[5:194, 4]
temp <- read.csv("temp.csv", stringsAsFactors=FALSE)
t <- temp[5:194, 4]
t
arrange(t)
grep("^United",temp[5:194, 4])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "temp.csv", method = "curl")
gdp <- read.csv("temp.csv", skip = 4, stringsAsFactors=FALSE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile = "temp.csv", method = "curl")
fed <- read.csv("temp.csv", stringsAsFactors=FALSE)
length(intersect(fed[, 1], head(gdp, 190)[, 1]))
intersect(fed[, 1], head(gdp, 190)[, 1])
cnt <- intersect(fed[, 1], head(gdp, 190)[, 1])
names(fed)
names(gdp)
head(fed)
head(gdp)
head(gdp, 10)
gdp
fed
View(fed)
fed %>% filter(Special.Notes)
?filter
fed %>% grep('iscal, Special.Notes, value=TRUE)
''
);
cqwfe
""
""
;';'
fed %>% grep("iscal", Special.Notes, value=TRUE)
grep("iscal", fed$Special.Notes, value=TRUE)
grep("iscal*June", fed$Special.Notes, value=TRUE)
grep("iscal.June", fed$Special.Notes, value=TRUE)
grep("iscal[.]June", fed$Special.Notes, value=TRUE)
grep("iscal.*June", fed$Special.Notes, value=TRUE)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.package("quantmod")
install("quantmod")
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
names(sampleTimes)
sampleTimes
years(sampleTimes)
months(sampleTimes)
sampleTimes > "2011-12-31"
length(sampleTimes > "2011-12-31" & sampleTimes < "2013-01-01")
sum(sampleTimes > "2011-12-31" & sampleTimes < "2013-01-01")
weekdays(sampleTimes)
weekdays(sampleTimes) = "Monday"
weekdays(sampleTimes) == "Monday"
sum(weekdays(sampleTimes) == "Monday")
sum(sampleTimes > "2011-12-31" & sampleTimes < "2013-01-01" & weekdays(sampleTimes) == "Monday")
sum(sampleTimes > "2011-12-31" & sampleTimes < "2013-01-01")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
v
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print p
xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print.trellis(p)
print(p)
print(p)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot)
library(ggplot2)
install.packages("ggplot")
install.packages("ggplot2")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
ggplot(movies, aes(votes, rating))
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
setwd("/Users/soobrosa/Desktop/coursera/repdata_3")
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"), stringsAsFactors=F)
harmful <- subset(data, FATALITIES != 0 | INJURIES != 0, select=c(BGN_DATE, STATE, EVTYPE, FATALITIES, INJURIES))
harmful$BGN_DATE <- as.numeric(format(as.Date(as.character(harmful$BGN_DATE),"%m/%d/%Y %H:%M:%S"), "%Y"))
costly <- subset(data, PROPDMGEXP == "B" | CROPDMGEXP == "B", select=c(BGN_DATE, STATE, EVTYPE, PROPDMG, CROPDMG))
costly$BGN_DATE <- as.numeric(format(as.Date(as.character(costly$BGN_DATE),"%m/%d/%Y %H:%M:%S"), "%Y"))
costly$DMG <- costly$PROPDMG + costly$CROPDMG
rm(data)
library(dplyr)
library(ggplot2)
library(tidyr)
top <-
harmful %>%
group_by(EVTYPE) %>%
summarize(no_of_fatalities = sum(FATALITIES)) %>%
summarize(no_of_injuries = sum(INJURIES)) %>%
arrange(desc(no_of_fatalities))
View(harmfil)
View(harmful)
top <- costly %>% group_by(EVTYPE) %>% summarize(total_damage = sum(DMG), property_damage = sum(PROPDMG), crop_damage = sum(CROPDMG)) %>% arrange(desc(total_damage))
top <-
harmful %>%
group_by(EVTYPE) %>%
summarize(no_of_fatalities = sum(FATALITIES), no_of_injuries = sum(INJURIES)) %>%
arrange(desc(no_of_fatalities))
top[1:10, ]
