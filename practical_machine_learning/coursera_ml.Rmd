---
title: "Practical Machine Learning Prediction Assignment Writeup - Daniel Molnar, 09-24-2015"
output: html_document
---

Overview
=

This is a real world simulation on how to predict the manner subjects perform weight lifting exercises. N = 6 with various data collection points. A ~brute-force Random Forest does the job as ~always.

Background
=

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Setup
=

This approach is going to be quick and dirty, just like in a way you would be trying to come up with something 'good enough' in a fast moving, real business environment. Move fast, break things, you can always undo and correct later. After a short peek cut with an axe and measure with a micrometer.

```{r, warning=FALSE, results='hide'}
# load libraries
library(caret)
library(randomForest)

# get data
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
              destfile = "pml-training.csv", method="curl")
training <- read.csv("pml-training.csv", na.strings = "NA", header = T, stringsAsFactors = T)

#peek
str(training)
```

Preparation
=

Let's clear out all that's not really clear -- fix factors as numeric, remove columns with missing values or unneccessary boilerplate and remove near zero variance predictors. Split training into training and validation sets.

```{r}

# fix factors as numeric, but not user name and classe
factors <- sapply(training, is.factor)
factors[c(1:7, length(factors))] <- FALSE 
to_numeric <- function(x) {
    num <- suppressWarnings(as.numeric(as.character(x)))
}
training[, factors] <- lapply(training[factors], to_numeric)

# remove columns with missing
training_filtered_missing <- training[,(colSums(is.na(training)) == 0)]

# remove unneccessary boilerplate
boilerplates <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "num_window")
training_compacted <- training_filtered_missing[,!(names(training_filtered_missing) %in% boilerplates)]

# remove near zero variance predictors
near_zero <- nearZeroVar(training_compacted, saveMetrics=TRUE)
training_compacted <- training_compacted[,!near_zero$nzv]

# split
partition <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
training_production <- training_compacted[partition,]
validation_production <- training_compacted[-partition,]
```

Modelling
=

We try to fit a random forest model and check the model performance on the validation set.

```{r}
set.seed(20150924)

# fit model
random_forest_model <- train(classe ~ ., method = "rf", data = training_production,
               importance = T, trControl = trainControl(method = "cv", number = 2))
validation_prediction <- predict(random_forest_model, newdata=validation_production)

# check performance and important variables
confusionMatrix(validation_prediction, validation_production$classe)
importance <- varImp(random_forest_model)$importance
varImpPlot(random_forest_model$finalModel, main = "Predictors in Order of Importance", col = 1, type = 1, sort = TRUE)
```

The model generated by random forest has an accuracy of 0.9918. The out-of-sample error is 0.82% as of (1-0.9918)*100. It should be fine for a rough-rough approach.

Prediction
=

Now roll the same with the testing set and prepare predictions for submission. Based on 53 variables we ran a random forest with 2-fold cross validation (to optimize for computation time). All 20 test cases were correct.


```{r}
# prepare
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
              destfile = "pml-testing.csv", method="curl")
testing <- read.csv("pml-testing.csv", na.strings = "NA", header = T, stringsAsFactors = T)
testing[, factors] <- lapply(testing[factors], to_numeric)
testing_filtered_missing <- testing[,(colSums(is.na(testing)) == 0)]
boilerplates <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "num_window", "problem_id")
testing_compacted <- testing_filtered_missing[,!(names(testing_filtered_missing) %in% boilerplates)]
near_zero <- nearZeroVar(testing_compacted, saveMetrics=TRUE)
testing_compacted <- testing_compacted[,!near_zero$nzv]

# roll
testing_prediction <- predict(random_forest_model, newdata=testing_compacted)
write_files <- function(x) {
        n <- length(x)
        for (i in 1:n) {
                filename <- paste0("problem_id", i, ".txt")
                write.table(x[i], file=filename, quote=FALSE, row.names=FALSE, col.names=FALSE)
        }
}
write_files(testing_prediction)
```
